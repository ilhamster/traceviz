/*
	Copyright 2023 Google Inc.
	Licensed under the Apache License, Version 2.0 (the "License");
	you may not use this file except in compliance with the License.
	You may obtain a copy of the License at
		https://www.apache.org/licenses/LICENSE-2.0
	Unless required by applicable law or agreed to in writing, software
	distributed under the License is distributed on an "AS IS" BASIS,
	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	See the License for the specific language governing permissions and
	limitations under the License.
*/

package datasource

import (
	"fmt"
	"sort"
	"time"

	logtrace "github.com/ilhamster/traceviz/logviz/analysis/log_trace"
	"github.com/ilhamster/traceviz/server/go/category"
	"github.com/ilhamster/traceviz/server/go/color"
	continuousaxis "github.com/ilhamster/traceviz/server/go/continuous_axis"
	"github.com/ilhamster/traceviz/server/go/util"
	xychart "github.com/ilhamster/traceviz/server/go/xy_chart"
)

func handleTimeseriesQuery(coll *Collection, qf *queryFilters, series util.DataBuilder, reqOpts map[string]*util.V) error {
	// Handle query parameters.
	var binCount int64
	var aggregateBy string
	var err error
	for key, val := range reqOpts {
		switch key {
		case binCountKey:
			binCount, err = util.ExpectIntegerValue(val)
		case aggregateByKey:
			aggregateBy, err = util.ExpectStringValue(val)
		default:
			return fmt.Errorf("unsupported option '%s'", key)
		}
		if err != nil {
			return err
		}
	}
	if binCount <= 1 {
		return fmt.Errorf("timeseries bin count must be >1")
	}
	// Information about a single series.
	type seriesInfo struct {
		id   string
		name string
		// if nil, will be generated by hashing the name.
		colorSpace *color.Space
		points     []float64
	}
	// Based on aggregateBy, set up a helper, getSeriesInfo, to fetch the right
	// seriesInfo for a given log Entry.
	seriesInfoByName := map[string]*seriesInfo{}
	// getSeriesInfo must be defined by each supported aggregation type.
	var getSeriesInfo func(entry *logtrace.Entry) *seriesInfo
	switch aggregateBy {
	case levelNameKey:
		getSeriesInfo = func(entry *logtrace.Entry) *seriesInfo {
			if si, ok := seriesInfoByName[entry.Level.Identifier()]; ok {
				return si
			}
			si := &seriesInfo{
				id:         entry.Level.Identifier(),
				name:       entry.Level.String(),
				colorSpace: colorSpacesByLevelWeight[entry.Level.Weight],
				points:     make([]float64, binCount),
			}
			seriesInfoByName[entry.Level.Identifier()] = si
			return si
		}
	default:
		return fmt.Errorf("unsupported aggregation type '%s'", aggregateBy)
	}
	// Figure out how wide each bin should be given the requested bin count.
	totalWidth := qf.duration()
	// The last bin will only contain samples at the last observed timestamp,
	// so we allocate the rest of the total width over (binCount-1) bins.
	// Each bin includes its lower bound and does not include its upper bound.
	binWidth := totalWidth / time.Duration(binCount-1)
	// Set the bin normalization factor, and the y-axis label, to the nearest
	// larger time unit.
	var binNormalization float64
	var binNormalizationLabel string
	switch {
	case binWidth >= time.Hour:
		binNormalization = float64(binWidth) / float64(time.Hour)
		binNormalizationLabel = "hour"
	case binWidth >= time.Minute:
		binNormalization = float64(binWidth) / float64(time.Minute)
		binNormalizationLabel = "minute"
	case binWidth >= time.Second:
		binNormalization = float64(binWidth) / float64(time.Second)
		binNormalizationLabel = "second"
	case binWidth >= time.Millisecond:
		binNormalization = float64(binWidth) / float64(time.Millisecond)
		binNormalizationLabel = "millisecond"
	case binWidth >= time.Microsecond:
		binNormalization = float64(binWidth) / float64(time.Microsecond)
		binNormalizationLabel = "microsecond"
	case binWidth >= time.Nanosecond:
		binNormalization = float64(binWidth) / float64(time.Nanosecond)
		binNormalizationLabel = "nanosecond"
	}
	// whichBin returns the bin index for a given Entry.
	whichBin := func(entry *logtrace.Entry) (int, error) {
		if entry.Time.Before(qf.startTimestamp) || entry.Time.After(qf.endTimestamp) {
			return 0, fmt.Errorf("entry is unexpectedly out of range")
		}
		startOffset := entry.Time.Sub(qf.startTimestamp)
		return int(startOffset / binWidth), nil
	}
	// For each filtered-in Entry, add that entry to the proper bin in its proper
	// seriesInfo, creating that seriesInfo if it doesn't exist.
	if err := coll.lt.ForEachEntry(func(entry *logtrace.Entry) error {
		si := getSeriesInfo(entry)
		bin, err := whichBin(entry)
		if err != nil {
			return err
		}
		si.points[bin]++
		return nil
	}, qf.filters(timeFilters, sourceFileFilter)); err != nil {
		return err
	}
	// Sort series output for test stability
	seriesNames := make([]string, 0, len(seriesInfoByName))
	for seriesName := range seriesInfoByName {
		seriesNames = append(seriesNames, seriesName)
	}
	sort.Strings(seriesNames)
	seriesColorSpaces := make([]util.PropertyUpdate, len(seriesNames))
	for idx, seriesName := range seriesNames {
		si := seriesInfoByName[seriesName]
		seriesColorSpaces[idx] = si.colorSpace.Define()
	}
	// Find the y-axis maximum.
	var yAxisMax float64
	for _, seriesName := range seriesNames {
		si := seriesInfoByName[seriesName]
		for _, dataPoint := range si.points {
			weight := dataPoint / binNormalization
			if weight > yAxisMax {
				yAxisMax = weight
			}
		}
	}
	// Emit the series data.
	chart := xychart.New(series,
		continuousaxis.NewTimestampAxis(
			category.New("x_axis", "Message timestamp", "Log message timestamp"),
			qf.startTimestamp, qf.endTimestamp),
		continuousaxis.NewDoubleAxis(
			category.New("y_axis", "Messages per "+binNormalizationLabel, "Log messages per "+binNormalizationLabel),
			0, yAxisMax), seriesColorSpaces...).With(
		xAxisRenderSettings.Apply(),
		yAxisRenderSettings.Apply(),
	)
	for _, seriesName := range seriesNames {
		si := seriesInfoByName[seriesName]
		timeseries := chart.AddSeries(
			category.New(si.id, si.name, si.name),
			si.colorSpace.PrimaryColor(1.0),
		)
		// For each point in the series, emit that point.
		binLow := qf.startTimestamp
		for _, dataPoint := range si.points {
			weight := dataPoint / binNormalization
			timeseries.WithPoint(
				binLow,
				weight,
			)
			binLow = binLow.Add(binWidth)
		}
	}
	return nil
}
